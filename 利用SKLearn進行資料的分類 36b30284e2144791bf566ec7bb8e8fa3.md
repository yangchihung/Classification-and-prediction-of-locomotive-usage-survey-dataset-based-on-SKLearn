# 利用SKLearn進行資料的分類

資工三1    楊啟弘    1410832005 

# 資料集介紹

---

本人因十分熱愛騎車或者開車，因此想要利用政府資料開放平臺上的109年機車使用狀況調查原始資料來進行分析，並利用資料集來進行機車種類的分類。

[機車使用狀況調查(Motorcycle Usage Survey)](https://data.gov.tw/dataset/6216)

## 內容

---

本資料集含有兩個檔案：一為原始資料，二為變數名稱。

內容包含了11364筆資料以及88個欄位。

![109年機車使用狀況調查原始資料](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%884.13.50.png)

109年機車使用狀況調查原始資料

![109年機車使用狀況調查原始資料＿變數名稱](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%884.14.53.png)

109年機車使用狀況調查原始資料＿變數名稱

由於欄位數量過多，所以只挑了部分欄位作為本次的分析，包含：

- YEAR：出廠年份
- TYPE：機車種類
- A4：本機車汰換後，是否會繼續購買機車
- A41：會購買何種類型的機車
- B1：本機車通常每公升汽油可行駛多少公里【電動機車免填】
- B2：本機車最常乘載人數：(含駕駛人)
- B3：本機車在年(109年)平均每星期使用幾天
- B41：本機車在平日有使用天數中，平均使用幾次
- B5：本機車在去年(109年)有使用天數中，平均一天行駛時間
- B6：本機車最主要用途
- B10：您平常出門除騎本機車外．是否也兼用其他交通工具
- D1：本機車平均每星期耗用汽油費、充電費或租用電池費
- D2：本機車去年(109年)全年保養維修費用
- D3：本機車去年(109年)平均每月花費停車費
- E1：您會不會購置或汰換改使用電動機車
- F2：性別
- F3：年齡
- F7：平均每月個人總所得

# 資料集分析

---

## 相互比較

```python
def heatmap_plot(data):

    plt.figure(figsize=(15,5))
    plt.title('Heatmap Correlation and Impact Distribution of Critics and Users')
    sns.heatmap(data[::].corr(), annot=True, cmap='mako', fmt='.3f')
    plt.show()
    
heatmap_plot(motor_data)
```

![截圖 2022-05-27 上午10.31.07.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-05-27_%E4%B8%8A%E5%8D%8810.31.07.png)

其中發現D1跟B5、A41跟E1有著相當的關係。

- D1 和 B5（每星期平均花費）、（平均一天行駛時間）(0.560)
    
    行駛時間越長，花費就越高。看起來十分合理！
    
- A41 和 E1（會購買何種機車）、（會不會購置或汰換改使用電動機車）(0.521)
    
    這就有點難分辨其中的關係了，來看一下兩者的關係吧！
    

```python
plt.figure( figsize=(10,5) )
gs = gridspec.GridSpec(1,1)    
ax = plt.subplot( gs[0] )
sns.countplot( motor_data['E1'], hue=motor_data.A41, palette=['lightcoral','lightblue','lightsalmon','lightseagreen','lightyellow'] )
ax.set_yticklabels([])
ax.set_ylabel( 'Counts' )
ax.legend( loc=1 ) 

for p in ax.patches:
    ax.annotate( '{:,}'.format(p.get_height()), (p.get_x(), p.get_height()+1.5) )

plt.show()
```

![截圖 2022-04-24 下午5.38.40.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%885.38.40.png)

- E1 的 1 跟 2 分別是不會改用電動機車跟會改用電動機車。
- A41的數字為機車種類， 1 為電動機車， 2 ~ 5 為機車c.c數，數字越高cc數越高。

其中可以看出購買電動機車的族群並大多不會再用電動機車的族群，購買普通重型機車的族群會改用電動機車。

## TYPE（機車種類）與其他特徵欄位的比較

```python
selected_cols = ['YEAR','A4','A41','B1','B2','B3','B41','B5','B6',
'B10','D1','D2','D3','E1','F2','F3','F7']

plt.figure( figsize=(10,len(selected_cols)*5) )
gs = gridspec.GridSpec(len(selected_cols),1)    
for i, col in enumerate( motor_data[selected_cols] ) :        
    ax = plt.subplot( gs[i] )
    sns.countplot( motor_data[col], hue=motor_data.TYPE, palette=['lightcoral','lightblue','lightsalmon','lightseagreen'] )
    ax.set_yticklabels([])
    ax.set_ylabel( 'Counts' )
    ax.legend( loc=1 )   
    for p in ax.patches:
        ax.annotate( '{:,}'.format(p.get_height()), (p.get_x(), p.get_height()+1.5) )
plt.show()
```

由於output太多，所以只放部分有發現關係的圖表。

TYPE 的數字 1  ~ 4 分別為

1. 電動機車
2. 輕型機車(不超過50cc)
3. 普通重型機車(超過50~250cc)
4. 普通大型機車(250cc及以上)

![普通重型機車在一週內使用最多天，普通大型機車則最少使用。](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%885.59.38.png)

普通重型機車在一週內使用最多天，普通大型機車則最少使用。

![普通重型機車平均一天使用時間隨著時間拉長數量逐漸減少，普通大型機車則持平。](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%885.59.57.png)

普通重型機車平均一天使用時間隨著時間拉長數量逐漸減少，普通大型機車則持平。

![電動、輕型、普通重型機車大多拿來上下班購物， 普通大型機車則大多拿來休閒。](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%886.00.15.png)

電動、輕型、普通重型機車大多拿來上下班購物， 普通大型機車則大多拿來休閒。

![大多數的普通大型機車會兼用其他交通工具。](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%888.31.50.png)

大多數的普通大型機車會兼用其他交通工具。

![普通大型機車的數量隨著保養費用提高而增加。](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%888.32.25.png)

普通大型機車的數量隨著保養費用提高而增加。

![持有普通大型機車的人大多是男性。](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%888.32.51.png)

持有普通大型機車的人大多是男性。

## TYPE（機車種類）的相關係數

利用corr( ) 函數來數據化的檢視TYPE與其他特徵欄位的關係。

```latex
Corr_Matrix = motor_data.corr()  
Corr = Corr_Matrix.loc['TYPE',:].sort_values()[:-1]
Corr = pd.DataFrame({ 'TYPE':Corr })
Corr
```

![截圖 2022-04-24 下午10.58.37.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%8810.58.37.png)

# 資料預處理

---

## 資料集的空值處理

在此資料集中有許多的空值，但並不是每個空值都代表未填。有些欄位的空值代表著「否」的意思，所以檢查過後，把代表「否」的空值補上 0 。

## 刪除遺漏值過多的資料與欄位

先檢視資料集的遺漏情況

```python
def Missing_Counts( Data ) : 
    missing = Data.isnull().sum()  
    missing = missing[ missing>0 ]
    missing.sort_values( inplace=True ) 
    
    Missing_Count = pd.DataFrame( { 'ColumnName':missing.index, 'MissingCount':missing.values } ) 
    Missing_Count[ 'Percentage(%)' ] = Missing_Count['MissingCount'].apply( lambda x:round(x/Data.shape[0]*100,2) )
    return  Missing_Count

print( 'miss :' )
display( Missing_Counts(motor_data) )
```

![截圖 2022-04-24 下午9.08.56.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%889.08.56.png)

把遺漏比例太多的欄位刪除，另外也把遺漏太多欄位的資料也刪除。

刪除之後：

![截圖 2022-04-24 下午9.12.04.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%889.12.04.png)

之後再用中位數去補空值。

```python
motor_data['A4'].fillna( motor_data.A4.median(), inplace=True )
motor_data['A41'].fillna( motor_data.A41.median(), inplace=True )
motor_data['B1'].fillna( motor_data.B1.median(), inplace=True )
motor_data['B41'].fillna( motor_data.B41.median(), inplace=True )
motor_data['B5'].fillna( motor_data.B5.median(), inplace=True )
motor_data['B10'].fillna( motor_data.B10.median(), inplace=True )
motor_data['D1'].fillna( motor_data.D1.median(), inplace=True )
motor_data['D2'].fillna( motor_data.D2.median(), inplace=True )
motor_data['D3'].fillna( motor_data.D3.median(), inplace=True )
motor_data['E1'].fillna( motor_data.E1.median(), inplace=True )
motor_data['F7'].fillna( motor_data.F7.median(), inplace=True )
```

## OneHot Encoding

---

對於定性且無序的特徵欄位，像是或否、性別，可以使用 get_dummies( ) 函數執行OneHot Encoding，將其轉換成定量資料。

```python
OneHot_A4 = pd.get_dummies( motor_data.A4, prefix='A4' )
OneHot_A41 = pd.get_dummies( motor_data.A41, prefix='A41' )
OneHot_E1 = pd.get_dummies( motor_data.E1, prefix='E1' )
OneHot_F2 = pd.get_dummies( motor_data.F2, prefix='F2' )

motor_data = pd.concat( [ motor_data, OneHot_A4, OneHot_A41, OneHot_E1, OneHot_F2 ], axis=1 )
motor_data.drop( ['A4','A41','E1','F2'], axis=1, inplace=True )
```

# 訓練模型

---

## 步驟

1. 分割資料
2. 測試隨機樹分類器
3. 測試決策數分類器
4. 測試KNN曼哈頓距離分類器
5. 測試KNN歐幾里得距離分類器

### 分割資料

將資料集中的目標特徵欄位（TYPE）拆開。

```python
motor_target = motor_data.TYPE
motor_data.drop( 'TYPE', axis=1, inplace=True )
```

使用"train_test_spit"將數據分成訓練和測試兩類。

```python
X_train, X_test, y_train, y_test = train_test_split(motor_data, motor_target, test_size = 0.2)

print( f'Shape of X_train = {X_train.shape}' )
print( f'Shape of y_train = {y_train.shape}' )
print( f'Shape of X_test = {X_test.shape}' )
```

![截圖 2022-04-24 下午9.52.13.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%889.52.13.png)

### 測試隨機樹分類器

```python
for split in range(10, 15):
    for leaf in range(1, 3):
        RFC = RandomForestClassifier( n_estimators = 1000,
                              min_samples_split = split,
                              min_samples_leaf = leaf,
                              oob_score = True,
                              random_state = 1,
                              n_jobs = -1 ) 
        RFC.fit( X_train, y_train )
        print( 'score = {:.6f}'.format(RFC.oob_score_) )
```

![截圖 2022-04-24 下午10.23.09.png](%E5%88%A9%E7%94%A8SKLearn%E9%80%B2%E8%A1%8C%E8%B3%87%E6%96%99%E7%9A%84%E5%88%86%E9%A1%9E%2036b30284e2144791bf566ec7bb8e8fa3/%E6%88%AA%E5%9C%96_2022-04-24_%E4%B8%8B%E5%8D%8810.23.09.png)

### 測試決策數分類器

```python
y_pred = tree.predict(X_test)
metrics.accuracy_score(y_test, y_pred)
```

`score = 0.863718`

### 測試KNN曼哈頓距離分類器

```python
knn = KNeighborsClassifier(p = 1)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
metrics.accuracy_score(y_test, y_pred)
```

`score = 0.882484`

### 測試KNN歐幾里德距離分類器

```python
knn = KNeighborsClassifier(p = 2)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)
metrics.accuracy_score(y_test, y_pred)
```

`score = 0.864611`

### 小結

似乎是因為資料數量以及特徵欄位夠多，模型的準確率都蠻高的。比較奇怪的是隨機樹分類器，不管在過程中改了些許資料欄位，其準確率都是 92 %，我猜測應該是出問題了。

# 結論與心得

---

在這次處理資料集中，讓我體會到資料集前處理是多麽的費時費力，也讓我意識到選到一個好資料集是本次過程中最重要的事。一個好的資料集能讓你上天堂，同時壞的資料集能讓你痛不欲生。

雖然這筆交資料集的欄位和資料非常足夠，在預處理上還算得心應手，但就結果上並沒有達到我可以從中發現新關係的期待。許多關係早已是普遍認知到的事。我期望下次期末會挑選到更有趣、更適合的資料集。

# 參考資料

---

- [政府資料開放平臺 交通部統計處機車使用狀況調查](https://data.gov.tw/dataset/6216)
- [[Python 商業數據分析之可視化繪圖] 第19講： 熱力圖（Seaborn-Heatmap）](https://medium.com/python-資料視覺化/python-商業數據分析之可視化繪圖-第19講-熱力圖-seaborn-heatmap-cf1b17d7964e)
- [Learning Pandas - 處理空值的資料和使用多重index](https://ithelp.ithome.com.tw/articles/10200052)
- [[Pandas教學]3個Pandas套件合併多個CSV檔案資料的實用技巧](https://www.learncodewithmike.com/2021/05/pandas-merge-multiple-csv-files.html)
- [Scikit-Learn 3 如何选择机器学习方法 (机器学习 sklearn 教学教程tutorial)](https://www.youtube.com/watch?v=GB8SNR-cT7w&list=PLXO45tsB95cI7ZleLM5i3XXhhe9YmVrRO&index=5)
- [[L3] Classification Exercise.pdf_完整程式碼](https://github.com/Anuise/Pythonpractice-/blob/master/sort/SKlearn)
- [使用Sklearn進行資料的分類及分群](https://medium.com/@jean841115/使用sklearn進行資料的分類及分群-98cb3b01f8cb)